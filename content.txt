
./terraform/outputs.tf # Print the file path
-------------------------------
# outputs.tf

# Capture master node IPs
output "master_ips" {
  value = [for vm in module.kubernetes_vms.compute_master : vm.ip_address]
}

# Capture master node MAC addresses
output "master_macs" {
  value = [for vm in module.kubernetes_vms.compute_master : vm.mac_addrs]
}

# Capture worker node IPs
output "worker_ips" {
  value = [for vm in module.kubernetes_vms.compute_worker : vm.ip_address]
}

# Capture worker node MAC addresses
output "worker_macs" {
  value = [for vm in module.kubernetes_vms.compute_worker : vm.mac_addrs]
} # Print file contents as-is
-------------------------------


./terraform/main.tf # Print the file path
-------------------------------
# main.tf
terraform {
    required_version = ">= 0.13.0"
    required_providers {
        proxmox = {
            source = "telmate/proxmox"
            version = "3.0.1-rc1"
        }
    }
}

provider "proxmox" {
  pm_api_url          = var.proxmox_api_url
  pm_api_token_id     = var.proxmox_api_token_id
  pm_api_token_secret = var.proxmox_api_token_secret
  pm_tls_insecure     = true
}

# Importing network/base VMs other then PfSense (Fedora, Ubuntu Server)
# module "network_vms" {
#   source       = "./modules/network"
#   vm_id_min    = 101
#   vm_id_max    = 199
#   storage_pool = var.storage_pool
#   target_node  = var.target_node
# }

# Importing service VMs (Mattermost, GitLab, etc.)
module "service_vms" {
  source       = "./modules/service"
  vm_id_min    = 200
  vm_id_max    = 299
  storage_pool = var.storage_pool
  target_node  = var.target_node
}

# Importing Kubernetes VMs (Talos Control and Worker Nodes)
module "kubernetes_vms" {
  source         = "./modules/kubernetes"
  vm_id_min      = 300
  vm_id_max      = 399
  talos_version = var.talos_version
  storage_pool   = var.storage_pool
  target_node    = var.target_node
}

# Importing database VMs (PostgreSQL, MongoDB, etc.)
module "database_vms" {
  source       = "./modules/database"
  vm_id_min    = 400
  vm_id_max    = 499
  storage_pool = var.storage_pool
  target_node  = var.target_node
} # Print file contents as-is
-------------------------------


./terraform/modules/database/main.tf # Print the file path
-------------------------------
# modules/database/main.tf
variable "vm_id_min" { type = number }
variable "vm_id_max" { type = number }
variable "storage_pool" { type = string }
variable "target_node" { type = string }

# Define PostgreSQL VM
resource "proxmox_lxc" "postgresql" {
  vmid       = var.vm_id_min
  hostname   = "postgresql"
  ostemplate = "${var.storage_pool}:vztmpl/{var.postgresql_ct_template}"
  target_node = var.target_node
  cores      = 2
  memory     = 4096
  rootfs     = "${var.storage_pool}:96G"
  network {
    name   = "eth0"
    bridge = "vmbr1"
    ip     = "dhcp"
  }
} # Print file contents as-is
-------------------------------


./terraform/modules/network/main.tf # Print the file path
-------------------------------
# modules/network/main.tf

variable "vm_id_min" { type = number }
variable "vm_id_max" { type = number }
variable "storage_pool" { type = string }
variable "target_node" { type = string }

# Define Fedora VM
resource "proxmox_vm_qemu" "fedora" {
  vmid         = var.vm_id_min + 1
  name         = "fedora"
  memory       = 4096
  cores        = 2
  target_node  = var.target_node

  # Disk configuration
  disk {
    size    = "32G"
    storage = var.storage_pool
  }

  # Attach the Fedora ISO image
  cdrom {
    file    = "${var.storage_pool}:iso/{var.fedora_iso_template}"
  }

  # Network interface
  network {
    model  = "virtio"
    bridge = "vmbr1"  # MAC will be generated automatically
    firewall = true
  }
} # Print file contents as-is
-------------------------------


./terraform/modules/service/main.tf # Print the file path
-------------------------------
# modules/service/main.tf
variable "vm_id_min" { type = number }
variable "vm_id_max" { type = number }
variable "storage_pool" { type = string }
variable "target_node" { type = string }

# Define Mattermost VM
resource "proxmox_lxc" "mattermost" {
  vmid       = var.vm_id_min
  hostname   = "mattermost"
  ostemplate = "${var.storage_pool}:vztmpl/{var.mattermost_ct_template}"
  target_node = var.target_node
  cores      = 2
  memory     = 4096
  rootfs     = "${var.storage_pool}:16G"
  network {
    name   = "eth0"
    bridge = "vmbr1"
    ip     = "dhcp"
  }
} # Print file contents as-is
-------------------------------


./terraform/modules/kubernetes/locals.tf # Print the file path
-------------------------------
locals {
  # Master Node configuration
  vm_master_nodes = {
    "0" = {
      vm_id          = var.vm_id_min
      node_name      = "talos-master-00"
      clone_target   = "talos-${var.talos_version}-cloud-init-template"
      node_cpu_cores = "2"
      node_memory    = 2048
      node_disk      = "16" # in GB
    }
    "1" = {
      vm_id          = var.vm_id_min + 1
      node_name      = "talos-master-01"
      clone_target   = "talos-${var.talos_version}-cloud-init-template"
      node_cpu_cores = "2"
      node_memory    = 2048
      node_disk      = "16" # in GB
    }
    "2" = {
      vm_id          = var.vm_id_min + 2
      node_name      = "talos-master-02"
      clone_target   = "talos-${var.talos_version}-cloud-init-template"
      node_cpu_cores = "2"
      node_memory    = 2048
      node_disk      = "16" # in GB
    }
  }
  # Worker Node configuration
  vm_worker_nodes = {
    "0" = {
      vm_id                = var.vm_id_min + 10
      node_name            = "talos-worker-00"
      clone_target         = "talos-${var.talos_version}-cloud-init-template"
      node_cpu_cores       = "4"
      node_memory          = 6144
      node_disk            = "16"
      additional_node_disk = "32" # for longhorn
    }
    "1" = {
      vm_id                = var.vm_id_min + 11
      node_name            = "talos-worker-01"
      clone_target         = "talos-${var.talos_version}-cloud-init-template"
      node_cpu_cores       = "4"
      node_memory          = 6144
      node_disk            = "16"
      additional_node_disk = "32" # for longhorn
    }
    "2" = {
      vm_id                = var.vm_id_min + 12
      node_name            = "talos-worker-02"
      clone_target         = "talos-${var.talos_version}-cloud-init-template"
      node_cpu_cores       = "4"
      node_memory          = 6144
      node_disk            = "16"
      additional_node_disk = "32" # for longhorn
    }
  }
} # Print file contents as-is
-------------------------------


./terraform/modules/kubernetes/main.tf # Print the file path
-------------------------------
# modules/kubernetes/main.tf
variable "vm_id_min" { type = number }
variable "vm_id_max" { type = number }
variable "storage_pool" { type = string }
variable "target_node" { type = string }
variable "talos_version" { type = string }

# Dynamically create VMs.
module "compute_master" {
  source                   = "./compute-master"
  target_node              = var.target_node
  storage_pool             = var.storage_pool
  nodes                    = local.vm_master_nodes
}
module "compute_worker" {
  source                   = "./compute-worker"
  target_node              = var.target_node
  storage_pool             = var.storage_pool
  nodes                    = local.vm_worker_nodes
} # Print file contents as-is
-------------------------------


./terraform/modules/kubernetes/compute-master/main.tf # Print the file path
-------------------------------
# Create a new VM from a clone
variable "nodes" {}
variable "storage_pool" { type = string }
variable "target_node" { type = string }

resource "proxmox_vm_qemu" "c0depool-talos" {

    # Dynamic provisioning of multiple nodes
    count = length(var.nodes)

    # VM General Settings
    target_node = var.target_node
    name = var.nodes[count.index].node_name
    vmid = var.nodes[count.index].vm_id

    # VM Advanced General Settings
    onboot = true 

    # VM OS Settings
    clone = var.nodes[count.index].clone_target

    # VM System Settings
    agent = 0
    
    # VM CPU Settings
    cores = var.nodes[count.index].node_cpu_cores
    sockets = 1
    cpu = "host"    
    
    # VM Memory Settings
    memory = var.nodes[count.index].node_memory

    # VM Network Settings
    network {
        bridge = "vmbr1"
        model  = "virtio"
    }

    # VM Disk Settings
    scsihw = "virtio-scsi-single"
    disks {
        scsi {
            scsi0 {
                disk {
                    size = var.nodes[count.index].node_disk
                    format    = "raw"
                    iothread  = true
                    backup    = false
                    storage   = var.storage_pool
                }
            }
        }
    }

    # VM Cloud-Init Settings
    os_type = "cloud-init"
    cloudinit_cdrom_storage = var.storage_pool
}

output "mac_addrs" {
    value = [for value in proxmox_vm_qemu.c0depool-talos : lower(tostring(value.network[0].macaddr))]
} # Print file contents as-is
-------------------------------


./terraform/modules/kubernetes/compute-worker/main.tf # Print the file path
-------------------------------
# Create a new VM from a clone
variable "nodes" {}
variable "storage_pool" { type = string }
variable "target_node" { type = string }

resource "proxmox_vm_qemu" "c0depool-talos" {

    # Dynamic provisioning of multiple nodes
    count = length(var.nodes)

    # VM General Settings
    target_node = var.target_node
    name = var.nodes[count.index].node_name
    vmid = var.nodes[count.index].vm_id

    # VM Advanced General Settings
    onboot = true

    # VM OS Settings
    clone = var.nodes[count.index].clone_target

    # VM System Settings
    agent = 0
    
    # VM CPU Settings
    cores = var.nodes[count.index].node_cpu_cores
    sockets = 1
    cpu = "host"    
    
    # VM Memory Settings
    memory = var.nodes[count.index].node_memory

    # VM Network Settings
    network {
        bridge = "vmbr1"
        model  = "virtio"
    }

    # VM Disk Settings
    scsihw = "virtio-scsi-single"
    disks {
        scsi {
            scsi0 {
                disk {
                    size = var.nodes[count.index].node_disk
                    format    = "raw"
                    iothread  = true
                    backup    = false
                    storage   = var.storage_pool
                }
            }
            scsi1 {
                disk {
                    size = var.nodes[count.index].additional_node_disk
                    format    = "raw"
                    iothread  = true
                    backup    = false
                    storage   = var.storage_pool
                }
            }
        }
    }

    # VM Cloud-Init Settings
    os_type = "cloud-init"
    cloudinit_cdrom_storage = var.storage_pool
}

output "mac_addrs" {
    value = [for value in proxmox_vm_qemu.c0depool-talos : lower(tostring(value.network[0].macaddr))]
} # Print file contents as-is
-------------------------------


./terraform/vars.tf # Print the file path
-------------------------------
# vars.tf
variable "proxmox_api_url" {
  description = "Proxmox API url address"
  type        = string
}

variable "proxmox_api_token_id" {
  description = "Proxmox API token ID"
  type        = string
}

variable "proxmox_api_token_secret" {
  description = "Proxmox API token secret"
  type        = string
}

variable "target_node" {
  description = "Target Proxmox node for VM deployment"
  type        = string
  default     = "pve"
}

variable "storage_pool" {
  description = "Default storage pool for VMs"
  type        = string
  default     = "local"
}

variable "talos_version" {
  description = "Talos version for target clone of packer vm"
  type        = string
}

variable "talos_disk_image_id" {
  type    = string
}

# VM/CT Templates
variable "mattermost_ct_template" {
  description = "Mattermost CT Template ID"
  type        = string
}

variable "postgresql_ct_template" {
  description = "PostgreSQL CT Template ID"
  type        = string
}

variable "pfsense_iso_template" {
  description = "PfSense ISO Template ID"
  type        = string
}

variable "fedora_iso_template" {
  description = "Fedora ISO Template ID"
  type        = string
}

variable "ubuntu_server_iso_template" {
  description = "Ubuntu Server ISO Template ID"
  type        = string
} # Print file contents as-is
-------------------------------


./README.md # Print the file path
-------------------------------
# gitlab-proxmox

InfraOps Guide for Gitlab CI/CD Setup with Hetzner + CloudFlare + Proxmox + PfSense + HaProxy

```bash
chmod -R +x ./
``` # Print file contents as-is
-------------------------------


./scripts/terraform/run-terraform.sh # Print the file path
-------------------------------
#!/bin/bash

# Color output functions
red() { echo -e "[31m$1[0m"; }
green() { echo -e "[32m$1[0m"; }
blue() { echo -e "[34m$1[0m"; }
cyan() { echo -e "[36m$1[0m"; }


# Define paths
PROXMOX_SETUP_DIR="$HOME/proxmox-setup"
PACKER_DIR="$PROXMOX_SETUP_DIR/packer"
TERRAFORM_DIR="$PROXMOX_SETUP_DIR/terraform"

# Function to provide Proxmox VM setup instructions
build_packer() {
    blue "Building Packer image..."
    cd $PACKER_DIR/talos-packer/
    packer init -upgrade .
    packer validate -var-file="vars/local.pkrvars.hcl" .
    packer build -var-file="vars/local.pkrvars.hcl" .
    green "Packer image built successfully!"
}

# Function to build Terraform
build_terraform() {
    blue "Building Terraform configuration..."
    cd $TERRAFORM_DIR/
    # Initialize Terraform
    terraform init
    # Plan
    terraform plan -out .tfplan
    # Apply
    terraform apply .tfplan
    green "Terraform configuration applied successfully!"
}

# Main function
main() {
    build_packer
    build_terraform
}

# Call the main function
main # Print file contents as-is
-------------------------------


./scripts/terraform/setup-terraform.sh # Print the file path
-------------------------------
#!/bin/bash

# Color output functions
red() { echo -e "[31m$1[0m"; }
green() { echo -e "[32m$1[0m"; }
blue() { echo -e "[34m$1[0m"; }
cyan() { echo -e "[36m$1[0m"; }


# Define paths
PROXMOX_SETUP_DIR="$HOME/proxmox-setup"
PACKER_DIR="$PROXMOX_SETUP_DIR/packer"
TERRAFORM_DIR="$PROXMOX_SETUP_DIR/terraform"

# Function to provide Proxmox user setup instructions
setup_proxmox_user_instructions() {
  cyan "=================================================="
  cyan "Setting up the necessary user and API token for Terraform in Proxmox"
  cyan "Follow these steps carefully to ensure Terraform can access Proxmox via API:"
  cyan ""
  cyan "1. Create a new user in Proxmox for Terraform"
  cyan "   Go to: Datacenter > Permissions > Users > Add"
  cyan "   Set the following values:"
  cyan "     - User name: terraform-user"
  cyan "     - Realm: pam (Linux PAM standard authentication)"
  cyan "     - Expire: never"
  cyan "     - Enabled: Yes"
  cyan "   Then click 'Add' to create the user."
  cyan ""
  cyan "2. Assign permissions to 'terraform-user'"
  cyan "   Go to: Datacenter > Permissions > Add"
  cyan "   Set the following values:"
  cyan "     - Path: '/' (This grants permissions at the root level)"
  cyan "     - User: terraform-user@pam"
  cyan "     - Role: PVEVMAdmin"
  cyan "   Then click 'Add' to save."
  cyan ""
  cyan "3. Generate an API token for 'terraform-user'"
  cyan "   Go to: Datacenter > Permissions > API Tokens > Add"
  cyan "   Set the following values:"
  cyan "     - User: terraform-user@pam"
  cyan "     - Token ID: terraform-token"
  cyan "     - Privilege Separation: Uncheck"
  cyan "     - Expire: never"
  cyan "   After clicking 'Add', save the generated token. This token will only be visible once, so be sure to copy it!"
  cyan "=================================================="
  cyan ""
}

# Function to prompt for Proxmox details
prompt_proxmox_details() {
  read -p "Enter Proxmox Server IP: " PROXMOX_SERVER_IP
  read -p "Enter Proxmox Token ID (default: terraform-user@pam!terraform-token): " PROXMOX_TOKEN_ID
  PROXMOX_TOKEN_ID=${PROXMOX_TOKEN_ID:-"terraform-user@pam!terraform-token"}
  read -p "Enter Proxmox Token Secret: " PROXMOX_TOKEN_SECRET
  read -p "Enter Proxmox Node (default: pve-01): " PROXMOX_NODE
  PROXMOX_NODE=${PROXMOX_NODE:-"pve-01"}
  read -p "Enter the Proxmox Storage Pool (default: local): " STORAGE_POOL
  STORAGE_POOL=${STORAGE_POOL:-"local"}

  export TF_VAR_proxmox_token_id="$PROXMOX_TOKEN_ID"
  export TF_VAR_proxmox_token_secret="$PROXMOX_TOKEN_SECRET"
}

# Function to check or generate SSH key
generate_ssh_key() {
  if [[ ! -f ~/.ssh/id_rsa ]]; then
    blue "Generating SSH key..."
    ssh-keygen -t rsa -b 2048 -f ~/.ssh/id_rsa -N ""
    green "SSH key generated at ~/.ssh/id_rsa"
  else
    green "SSH key already exists at ~/.ssh/id_rsa"
  fi
}

# Function to prompt for template and image details
prompt_template_and_image_details() {
  blue "Please provide the following Proxmox templates and images details:"

  read -p "Enter PfSense ISO Template ID (default: netgate-installer-amd64.iso): " PFSENSE_ISO_TEMPLATE
  PFSENSE_ISO_TEMPLATE=${PFSENSE_ISO_TEMPLATE:-"netgate-installer-amd64.iso"}
  read -p "Enter Fedora ISO Template ID (default: Fedora-Workstation-Live-x86_64-40-1.14.iso): " FEDORA_ISO_TEMPLATE
  FEDORA_ISO_TEMPLATE=${FEDORA_ISO_TEMPLATE:-"Fedora-Workstation-Live-x86_64-40-1.14.iso"}
  read -p "Enter Ubuntu Server ISO Template ID (default: ubuntu-24.04.1-live-server-amd64.iso): " UBUNTU_SERVER_ISO_TEMPLATE
  UBUNTU_SERVER_ISO_TEMPLATE=${UBUNTU_SERVER_ISO_TEMPLATE:-"ubuntu-24.04.1-live-server-amd64.iso"}

  read -p "Enter Packer Base ISO File (default: archlinux-2024.10.01-x86_64.iso): " BASE_ISO_FILE
  BASE_ISO_FILE=${BASE_ISO_FILE:-"archlinux-2024.10.01-x86_64.iso"}
  read -p "Enter Talos Disk Image schematic ID (default: ce4c980550dd2ab1b17bbf2b08801c7eb59418eafe8f279833297925d67c7515): " TALOS_DISK_IMAGE_ID
  TALOS_DISK_IMAGE_ID=${TALOS_DISK_IMAGE_ID:-"ce4c980550dd2ab1b17bbf2b08801c7eb59418eafe8f279833297925d67c7515"}
  read -p "Enter Talos Disk Image version number (default: v1.8.2): " TALOS_VERSION
  TALOS_VERSION=${TALOS_VERSION:-"v1.8.2"}

  read -p "Enter Mattermost CT Template ID (default: debian-12-turnkey-mattermost_18.0-1_amd64.tar.gz): " MATTERMOST_CT_TEMPLATE
  MATTERMOST_CT_TEMPLATE=${MATTERMOST_CT_TEMPLATE:-"debian-12-turnkey-mattermost_18.0-1_amd64.tar.gz"}
  read -p "Enter PostgreSQL CT Template ID (default :debian-12-turnkey-postgresql_18.1-1_amd64.tar.gz ): " POSTGRESQL_CT_TEMPLATE
  POSTGRESQL_CT_TEMPLATE=${POSTGRESQL_CT_TEMPLATE:-"debian-12-turnkey-postgresql_18.1-1_amd64.tar.gz"}
}

# Function to create packer configuration file
create_packer_configuration() {
  mkdir -p $PACKER_DIR/talos-packer/vars
  blue "Creating Packer local.pkvars.hcl configuration..."

  cat > $PACKER_DIR/talos-packer/vars/local.pkvars.hcl <<EOL
proxmox_api_url       = "https://$PROXMOX_SERVER_IP:8006/api2/json"
proxmox_node          = "$PROXMOX_NODE"
proxmox_api_token_id  = "$PROXMOX_TOKEN_ID"
proxmox_api_token_secret = "$PROXMOX_TOKEN_SECRET"
proxmox_storage       = "$STORAGE_POOL"
cpu_type              = "host"
base_iso_file         = "local:iso/$BASE_ISO_FILE"
talos_version         = "$TALOS_VERSION"
talos_disk_image_id      = "$TALOS_DISK_IMAGE_ID"
EOL
  green "Packer local.pkvars.hcl created."
}

# Function to create Terraform credentials file
create_terraform_credentials() {
  blue "Creating Terraform credentials.auto.tfvars..."

  cat > $TERRAFORM_DIR/credentials.auto.tfvars <<EOL
proxmox_api_url          = "https://$PROXMOX_SERVER_IP:8006/api2/json"
proxmox_api_token_id     = "$PROXMOX_TOKEN_ID"
proxmox_api_token_secret = "$PROXMOX_TOKEN_SECRET"
target_node              = "$PROXMOX_NODE"
storage_pool             = "$STORAGE_POOL"
talos_version            = "$TALOS_VERSION"
talos_disk_image_id      = "$TALOS_DISK_IMAGE_ID"
EOL
  green "Terraform credentials.auto.tfvars created."
}

# Function to create images.tfvars for specifying templates
create_images_tfvars() {
  blue "Creating Terraform images.tfvars..."

  cat > $TERRAFORM_DIR/images.tfvars <<EOL
mattermost_ct_template   = "$MATTERMOST_CT_TEMPLATE"
postgresql_ct_template   = "$POSTGRESQL_CT_TEMPLATE"
pfsense_iso_template     = "$PFSENSE_ISO_TEMPLATE"
fedora_iso_template      = "$FEDORA_ISO_TEMPLATE"
ubuntu_server_iso_template = "$UBUNTU_SERVER_ISO_TEMPLATE"
EOL
  green "Terraform images.tfvars created."
}

# Main function
main() {
  setup_proxmox_user_instructions
  prompt_proxmox_details
  generate_ssh_key
  prompt_template_and_image_details
  create_packer_configuration
  create_terraform_credentials
  create_images_tfvars
}

# Call the main function
main # Print file contents as-is
-------------------------------


./scripts/talos/setup-talos.sh # Print the file path
-------------------------------
#!/bin/bash

# Color output functions for better readability
red() { echo -e "[31m$1[0m"; }
green() { echo -e "[32m$1[0m"; }
blue() { echo -e "[34m$1[0m"; }
cyan() { echo -e "[36m$1[0m"; }

# Define paths
PROXMOX_SETUP_DIR="$HOME/proxmox-setup"
TALOS_DIR="$PROXMOX_SETUP_DIR/talos"
TALOS_CONFIG_DIR="$TALOS_DIR/clusterconfig"
TERRAFORM_DIR="$PROXMOX_SETUP_DIR/terraform"
TALOS_CONFIG_FILE="$HOME/.talos/config"
KUBE_CONFIG_DIR="$HOME/.kube"
KUBE_CONFIG_FILE="$KUBE_CONFIG_DIR/config"


# Load values from Terraform outputs
MASTER_IPS=($(terraform -chdir="$TERRAFORM_DIR" output -json master_ips | jq -r '.[]'))
WORKER_IPS=($(terraform -chdir="$TERRAFORM_DIR" output -json worker_ips | jq -r '.[]'))
MASTER_MACS=($(terraform -chdir="$TERRAFORM_DIR" output -json master_macs | jq -r '.[]'))
WORKER_MACS=($(terraform -chdir="$TERRAFORM_DIR" output -json worker_macs | jq -r '.[]'))
TALOS_VERSION=$(terraform -chdir="$TERRAFORM_DIR" output -json talos_version | jq -r '.')
TALOS_DISK_IMAGE_ID=$(terraform -chdir="$TERRAFORM_DIR" output -json talos_disk_image_id | jq -r '.')


# Step 1: Generate Talos YAML configuration for cluster setup
generate_talos_yaml_config() {
    blue "Generating Talos cluster configuration YAML file..."

    cat > "$TALOS_CONFIG_FILE" <<EOF
# yaml-language-server: \$schema=https://raw.githubusercontent.com/budimanjojo/talhelper/master/pkg/config/schemas/talconfig.json
---
talosVersion: "${TALOS_VERSION}"
kubernetesVersion: "v1.30.0"

clusterName: "talos-cluster"
endpoint: "https://192.168.0.199:6443"
clusterPodNets:
  - "10.14.0.0/16"
clusterSvcNets:
  - "10.15.0.0/16"
additionalApiServerCertSans:
  - "192.168.0.199"
additionalMachineCertSans:
  - "192.168.0.199"

nodes:
  - hostname: "talos-master-00"
    controlPlane: true
    ipAddress: "${MASTER_IPS[0]}"
    installDisk: "/dev/sda"
    talosImageURL: "factory.talos.dev/installer/${TALOS_DISK_IMAGE_ID}:${TALOS_VERSION}"
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "${MASTER_MACS[0]}"
        dhcp: true
        vip:
          ip: "192.168.0.199"

  - hostname: "talos-master-01"
    controlPlane: true
    ipAddress: "${MASTER_IPS[1]}"
    installDisk: "/dev/sda"
    talosImageURL: "factory.talos.dev/installer/${TALOS_DISK_IMAGE_ID}:${TALOS_VERSION}"
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "${MASTER_MACS[1]}"
        dhcp: true
        vip:
          ip: "192.168.0.199"

  - hostname: "talos-master-02"
    controlPlane: true
    ipAddress: "${MASTER_IPS[2]}"
    installDisk: "/dev/sda"
    talosImageURL: "factory.talos.dev/installer/${TALOS_DISK_IMAGE_ID}:${TALOS_VERSION}"
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "${MASTER_MACS[2]}"
        dhcp: true
        vip:
          ip: "192.168.0.199"

  - hostname: "talos-worker-00"
    controlPlane: false
    ipAddress: "${WORKER_IPS[0]}"
    installDisk: "/dev/sda"
    talosImageURL: "factory.talos.dev/installer/${TALOS_DISK_IMAGE_ID}:${TALOS_VERSION}"
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "${WORKER_MACS[0]}"
        dhcp: true

  - hostname: "talos-worker-01"
    controlPlane: false
    ipAddress: "${WORKER_IPS[1]}"
    installDisk: "/dev/sda"
    talosImageURL: "factory.talos.dev/installer/${TALOS_DISK_IMAGE_ID}:${TALOS_VERSION}"
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "${WORKER_MACS[1]}"
        dhcp: true

  - hostname: "talos-worker-02"
    controlPlane: false
    ipAddress: "${WORKER_IPS[2]}"
    installDisk: "/dev/sda"
    talosImageURL: "factory.talos.dev/installer/${TALOS_DISK_IMAGE_ID}:${TALOS_VERSION}"
    networkInterfaces:
      - deviceSelector:
          hardwareAddr: "${WORKER_MACS[2]}"
        dhcp: true

patches:
  - |-
    cluster:
      network:
        cni:
          name: "cilium"
          config:
            ipam: "kubernetes"
            kubeProxyReplacement: true
            l2announcements:
              enabled: true
            externalIPs:
              enabled: true
            devices: "eth+"

controlPlane:
  patches:
    - |-
      cluster:
        controllerManager:
          extraArgs:
            bind-address: "0.0.0.0"
        scheduler:
          extraArgs:
            bind-address: "0.0.0.0"

worker:
  patches:
    - |-
      machine:
        kubelet:
          extraMounts:
            - destination: "/var/mnt/longhorn"
              type: "bind"
              source: "/var/mnt/longhorn"
              options:
                - "bind"
                - "rshared"
                - "rw"
        disks:
          - device: "/dev/sdb"
            partitions:
              - mountpoint: "/var/mnt/longhorn"
EOF
}


# Step 2: Generate Talos configuration using Talhelper
generate_talos_config() {
    cd "$TALOS_DIR" || exit

    # Generate Talos secret
    blue "Generating Talos secrets..."
    talhelper gensecret > talsecret.sops.yaml

    # Create Age secret key for Sops
    blue "Creating Age secret key..."
    mkdir -p "$HOME/.config/sops/age"
    age-keygen -o "$HOME/.config/sops/age/keys.txt"

    # Create .sops.yaml configuration for Sops
    cat <<EOF > "$TALOS_DIR/.sops.yaml"
---
creation_rules:
  - age: "$(grep -o 'age1.*' $HOME/.config/sops/age/keys.txt)"
EOF

    # Encrypt Talos secrets with Age and Sops
    blue "Encrypting Talos secrets..."
    sops -e -i talsecret.sops.yaml

    # Generate Talos configuration files
    blue "Generating Talos configuration files..."
    talhelper genconfig
    green "Talos configuration files generated in $TALOS_CONFIG_DIR."
}

# Step 3: Apply Talos configuration to nodes
apply_talos_config() {
    blue "Applying Talos configuration to master and worker nodes..."
    cd "$TALOS_DIR" || exit

    # Apply configuration for each master node
    for i in "${!MASTER_IPS[@]}"; do
        master_ip="${MASTER_IPS[$i]}"
        config_file="$TALOS_CONFIG_DIR/master-config-$i.yaml"
        blue "Applying configuration to master node at $master_ip"
        talosctl apply-config --insecure --nodes "$master_ip" --file "$config_file"
    done

    # Apply configuration for each worker node
    for i in "${!WORKER_IPS[@]}"; do
        worker_ip="${WORKER_IPS[$i]}"
        config_file="$TALOS_CONFIG_DIR/worker-config-$i.yaml"
        blue "Applying configuration to worker node at $worker_ip"
        talosctl apply-config --insecure --nodes "$worker_ip" --file "$config_file"
    done

    green "Configuration applied to all nodes. Waiting for nodes to reboot..."
    sleep 120  # Adjust this if nodes need more time to reboot
}

# Step 4: Bootstrap Talos on the cluster
bootstrap_talos_cluster() {
    local master_node_ip="${MASTER_IPS[0]}"

    # Set up Talos configuration
    mkdir -p "$(dirname "$TALOS_CONFIG_FILE")"
    cp "$TALOS_CONFIG_DIR/talosconfig" "$TALOS_CONFIG_FILE"

    # Run the bootstrap command on the first master node
    blue "Bootstrapping Talos on master node at IP $master_node_ip"
    talosctl bootstrap -n "$master_node_ip"

    # Generate kubeconfig for accessing the cluster
    mkdir -p "$KUBE_CONFIG_DIR"
    talosctl -n "$master_node_ip" kubeconfig "$KUBE_CONFIG_FILE"
    green "Kubeconfig saved to $KUBE_CONFIG_FILE"

    # Verify node status
    cyan "Verifying the status of nodes..."
    kubectl get nodes
}

# Step 5: Install Cilium as the networking solution
install_cilium() {
    blue "Installing Cilium for Kubernetes networking..."
    cilium install \
        --helm-set=ipam.mode=kubernetes \
        --helm-set=kubeProxyReplacement=true \
        --helm-set=securityContext.capabilities.ciliumAgent="{CHOWN,KILL,NET_ADMIN,NET_RAW,IPC_LOCK,SYS_ADMIN,SYS_RESOURCE,DAC_OVERRIDE,FOWNER,SETGID,SETUID}" \
        --helm-set=securityContext.capabilities.cleanCiliumState="{NET_ADMIN,SYS_ADMIN,SYS_RESOURCE}" \
        --helm-set=cgroup.autoMount.enabled=false \
        --helm-set=cgroup.hostRoot=/sys/fs/cgroup \
        --helm-set=l2announcements.enabled=true \
        --helm-set=externalIPs.enabled=true \
        --helm-set=devices=eth+
    kubectl get nodes
    kubectl get pods -A
}

# Step 6: Configure Cilium L2 Load Balancer IP Pool
configure_cilium_loadbalancer() {
    blue "Configuring Cilium Load Balancer IP Pool..."
    cat <<EOF | kubectl apply -f -
apiVersion: "cilium.io/v2alpha1"
kind: CiliumLoadBalancerIPPool
metadata:
  name: "cilium-lb-pool"
spec:
  cidrs:
  - cidr: "192.168.0.100/30"
EOF

    cat <<EOF | kubectl apply -f -
apiVersion: "cilium.io/v2alpha1"
kind: CiliumL2AnnouncementPolicy
metadata:
  name: "cilium-l2-policy"
spec:
  interfaces:
  - eth0
  externalIPs: true
  loadBalancerIPs: true
EOF
    green "Cilium L2 Load Balancer configured."
}

# Step 7: Install Ingress NGINX Controller with Cilium LoadBalancer
install_ingress_nginx() {
    blue "Installing Ingress NGINX Controller with Cilium LoadBalancer..."
    helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
    helm repo update
    helm install ingress-nginx ingress-nginx/ingress-nginx \
        --namespace ingress-nginx \
        --create-namespace \
        --set controller.externalTrafficPolicy="Local" \
        --set controller.kind="DaemonSet" \
        --set controller.service.annotations."io.cilium/lb-ipam-ips"="192.168.0.101"
    kubectl get svc ingress-nginx-controller -n ingress-nginx
}

# Step 8: Install Longhorn for storage
install_longhorn() {
    blue "Installing Longhorn as a storage solution..."
    helm repo add longhorn https://charts.longhorn.io
    helm repo update
    helm install longhorn longhorn/longhorn \
        --namespace longhorn-system \
        --create-namespace \
        --version 1.6.2 \
        --set defaultSettings.defaultDataPath="/var/mnt/longhorn"
    green "Longhorn installed. Talos Kubernetes cluster setup is complete!"
}

# Main function
main() {
    generate_talos_yaml_config
    generate_talos_config
    apply_talos_config
    bootstrap_talos_cluster
    install_cilium
    configure_cilium_loadbalancer
    install_ingress_nginx
    install_longhorn
}

# Execute the main function
main # Print file contents as-is
-------------------------------


./scripts/setup/install-tools.sh # Print the file path
-------------------------------
#!/bin/bash

# Color functions for output
red() { echo -e "[31m$1[0m"; }
green() { echo -e "[32m$1[0m"; }
blue() { echo -e "[34m$1[0m"; }

# Install prerequisites
install_prerequisites() {
    blue "Installing prerequisites..."
    sudo apt update
    sudo apt install -y gnupg software-properties-common curl wget apt-transport-https ca-certificates lsb-release
    green "Prerequisites installed."
}

# Install Packer
install_packer() {
    blue "Installing Packer..."
    wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
    echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
    sudo apt update && sudo apt install packer
    packer -v
    green "Docker installed."
}

# Install Terraform
install_terraform() {
    blue "Installing Terraform..."
    wget -O- https://apt.releases.hashicorp.com/gpg | \
    gpg --dearmor | \
    sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg > /dev/null
    echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \
    https://apt.releases.hashicorp.com $(lsb_release -cs) main" | \
    sudo tee /etc/apt/sources.list.d/hashicorp.list
    sudo apt update
    sudo apt install terraform
    terraform -v
    green "Terraform installed."
}

# Install Talosctl
install_talosctl() {
    blue "Installing Talosctl..."
    curl -sL https://talos.dev/install | sh
    talosctl version --help
    green "Talosctl installed."
}

# Install Talhelper
install_talhelper() {
    blue "Installing Talhelper..."
    curl https://i.jpillora.com/budimanjojo/talhelper! | sudo bash
    talhelper -v
    green "Talhelper installed."
}

# Install Kubernetes CLI tools
install_kubectl() {
    blue "Installing kubectl..."
    curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
    kubectl version --client
    green "kubectl installed."
}

# Install SOPS for secrets management
install_sops() {
    blue "Installing SOPS for secrets management..."
    curl -LO https://github.com/getsops/sops/releases/download/v3.8.1/sops-v3.8.1.linux.amd64
    mv sops-v3.8.1.linux.amd64 /usr/local/bin/sops
    chmod +x /usr/local/bin/sops
    sops -v
    green "SOPS installed."
}

# Install Age
install_age() {
    blue "Installing Age..."
    sudo apt install age
    age -version
    green "Age installed."
}

# Install Cilium CLI
install_cilium_cli() {
    blue "Installing Cilium CLI..."
    CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
    CLI_ARCH=amd64
    if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi
    curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
    sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum
    sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin
    rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
    green "Cilium CLI installed."
}

# Install Prometheus, Grafana, and Loki (for logging and monitoring)
install_monitoring_tools() {
    blue "Installing Prometheus, Grafana, and Loki..."
    sudo docker pull prom/prometheus
    sudo docker pull grafana/grafana
    sudo docker pull grafana/loki
    green "Monitoring tools installed."
}

# Main function
main() {
    install_prerequisites
    install_packer
    install_terraform
    install_talosctl
    install_talhelper
    install_kubectl
    install_sops
    install_age
    install_cilium_cli
    install_monitoring_tools
}

# Call the main function
main # Print file contents as-is
-------------------------------


./scripts/setup/setup-network.sh # Print the file path
-------------------------------
#!/bin/bash

# Color functions for output
red() { echo -e "[31m$1[0m"; }
green() { echo -e "[32m$1[0m"; }
blue() { echo -e "[34m$1[0m"; }

# Function to prompt for input with a default value
prompt_input() {
    local prompt=$1
    local default=$2
    read -p "$(blue "$prompt [$default]:") " input
    echo "${input:-$default}"
}

# Function to create bridge configuration for each additional IP
create_bridge_text() {
    local ip=$1
    local bridge_id=$2
    local mac_address=$3
    local external_bridge_id=$bridge_id
    local internal_bridge_id=$((bridge_id * 100))

    # WAN bridge configuration with MAC address and public IP
    local bridge_config="
auto vmbr${external_bridge_id}
iface vmbr${external_bridge_id} inet static
    address ${ip}
    netmask ${NETMASK}
    bridge_ports none
    bridge_stp off
    bridge_fd 0
    hwaddress ether ${mac_address}
#WAN ${external_bridge_id}
"

    # LAN bridge configuration without an IP, as it's for internal network only
    bridge_config+="
auto vmbr${internal_bridge_id}
iface vmbr${internal_bridge_id} inet manual
    bridge_ports none
    bridge_stp off
    bridge_fd 0
#LAN ${internal_bridge_id}
"
    echo "$bridge_config"
}

# Step 1: Collect network information
collect_network_info() {
    green "Collecting network configuration..."
    MAINSERVERIP=$(prompt_input "Main server IP" "192.168.0.1")
    GATEWAYADDRESS=$(prompt_input "Gateway address" "192.168.0.254")
    NETMASK=$(prompt_input "Netmask" "255.255.255.0")
    BROADCASTIP=$(prompt_input "Broadcast IP" "192.168.0.255")

    echo ""
    blue "Note: For Hetzner, ADDITIONAL_IP_ADDRESSES corresponds to the additional IPs listed under your server in the Hetzner Robot Console."
    blue "MAC_ADDRESSES correspond to the separate MAC addresses associated with each additional IP in the console."
    echo ""
    
    ADD_IP_ADDRESSES=$(prompt_input "Additional IPs (comma-separated)" "")
    MAC_ADDRESSES=$(prompt_input "MAC addresses for additional IPs (comma-separated)" "")
    NETWORK_INTERFACE=$(prompt_input "Network interface" "eth0")
}

# Step 2: Confirm configuration with the user
confirm_config() {
    green "You have entered the following configuration:"
    echo -e "Main server IP: $MAINSERVERIP
Gateway address: $GATEWAYADDRESS
Netmask: $NETMASK
Broadcast IP: $BROADCASTIP
Additional IPs: $ADD_IP_ADDRESSES
MAC addresses: $MAC_ADDRESSES
Network interface: $NETWORK_INTERFACE"
    read -p "$(blue "Is this correct? [yes/no]:") " confirmation
    [[ $confirmation != [Yy]* ]] && { red "Exiting without changes."; exit 1; }
}

# Step 3: Generate routing rules for additional IPs
generate_additional_routes() {
    additional_routes=""
    IFS=',' read -ra ADDR <<<"$ADD_IP_ADDRESSES"
    for add_ip in "${ADDR[@]}"; do
        additional_routes+="    up ip route add $add_ip dev ${NETWORK_INTERFACE}
"
    done
}

# Step 4: Generate configuration for /etc/network/interfaces
generate_interface_content() {
    green "Generating network interface configuration..."
    interfaces_content="
### Hetzner Online GmbH installimage

source /etc/network/interfaces.d/*

auto lo
iface lo inet loopback
iface lo inet6 loopback

iface ${NETWORK_INTERFACE} inet manual
    up ip route add -net ${GATEWAYADDRESS} netmask ${NETMASK} gw ${GATEWAYADDRESS} vmbr0
    up sysctl -w net.ipv4.ip_forward=1
    up sysctl -w net.ipv4.conf.${NETWORK_INTERFACE}.send_redirects=0
    up sysctl -w net.ipv6.conf.all.forwarding=1
$additional_routes
    up ip route add 192.168.0.0/16 via ${MAINSERVERIP} dev vmbr0
    up ip route add 172.16.0.0/12 via ${MAINSERVERIP} dev vmbr0
    up ip route add 10.0.0.0/8 via ${MAINSERVERIP} dev vmbr0

auto vmbr0
iface vmbr0 inet static
    address  ${MAINSERVERIP}
    netmask  ${NETMASK}
    gateway  ${GATEWAYADDRESS}
    broadcast  ${BROADCASTIP}
    bridge-ports ${NETWORK_INTERFACE}
    bridge-stp off
    bridge-fd 0
    pointopoint ${GATEWAYADDRESS}
#Main IP configuration
"
}

# Step 5: Add additional IP bridges to configuration
add_additional_bridges() {
    IFS=',' read -ra ADDR <<<"$ADD_IP_ADDRESSES"
    IFS=',' read -ra MACS <<<"$MAC_ADDRESSES"
    
    for i in "${!ADDR[@]}"; do
        bridge_id=$((i + 1))
        interfaces_content+=$(create_bridge_text "${ADDR[i]}" "$bridge_id" "${MACS[i]}")
    done
}

# Step 6: Apply the new configuration
apply_config() {
    green "Saving configuration to /etc/network/interfaces..."
    echo "$interfaces_content" > /tmp/new_interfaces
    timestamp=$(date +%Y%m%d-%H%M%S)
    mv /etc/network/interfaces /etc/network/interfaces.bak-$timestamp
    mv /tmp/new_interfaces /etc/network/interfaces
    green "Network configuration applied. Restart networking with: 'systemctl restart networking'"
}

# Main function
main() {
    collect_network_info
    confirm_config
    generate_additional_routes
    generate_interface_content
    add_additional_bridges
    apply_config
}

# Call the main function
main # Print file contents as-is
-------------------------------


./packer/content.txt # Print the file path
-------------------------------

./talos-packer/variables.pkr.hcl
-------------------------------
variable "proxmox_api_token_id" {
  type = string
}

variable "proxmox_api_token_secret" {
  type = string
}

variable "proxmox_api_url" {
  type = string
}

variable "proxmox_node" {
  type = string
}

variable "proxmox_storage" {
  type = string
}

variable "cpu_type" {
  type    = string
  default = "kvm64"
}

variable "cores" {
  type    = string
  default = "2"
}

variable "cloudinit_storage_pool" {
  type    = string
  default = "local"
}

variable "talos_version" {
  type    = string
  default = "v1.8.2"
}

variable "base_iso_file" {
  type    = string
}

locals {
  image = "https://github.com/talos-systems/talos/releases/download/${var.talos_version}/nocloud-amd64.raw.xz"
}
-------------------------------


./talos-packer/proxmox.pkr.hcl
-------------------------------
packer {
  required_plugins {
    proxmox = {
      version = ">= 1.0.1"
      source  = "github.com/hashicorp/proxmox"
    }
  }
}

source "proxmox-iso" "talos" {
  proxmox_url              = var.proxmox_api_url
  username                 = var.proxmox_api_token_id
  token                    = var.proxmox_api_token_secret
  node                     = var.proxmox_node
  insecure_skip_tls_verify = true

  iso_file    = "${var.base_iso_file}"
  unmount_iso = true

  scsi_controller = "virtio-scsi-single"
  network_adapters {
    bridge = "vmbr1"
    model  = "virtio"
  }
  disks {
    type              = "scsi"
    storage_pool      = var.proxmox_storage
    format            = "raw"
    disk_size         = "1500M"
    io_thread         = true
    cache_mode        = "writethrough"
  }

  memory               = 2048
  vm_id                = "9700"
  cores                = var.cores
  cpu_type             = var.cpu_type
  sockets              = "1"
  ssh_username         = "root"
  ssh_password         = "packer"
  ssh_timeout          = "15m"

  cloud_init              = true
  cloud_init_storage_pool = var.cloudinit_storage_pool

  template_name        = "talos-${var.talos_version}-cloud-init-template"
  template_description = "Talos ${var.talos_version} cloud-init, built on ${formatdate("YYYY-MM-DD hh:mm:ss ZZZ", timestamp())}"

  boot_wait = "25s"
  boot_command = [
    "<enter><wait1m>",
    "passwd<enter><wait>packer<enter><wait>packer<enter>"
  ]
}

build {
  sources = ["source.proxmox-iso.talos"]

  provisioner "shell" {
    inline = [
      "curl -s -L ${local.image} -o /tmp/talos.raw.xz",
      "xz -d -c /tmp/talos.raw.xz | dd of=/dev/sda && sync",
    ]
  }
}
-------------------------------


./talos-packer/vars/local.pkrvars.hcl
-------------------------------
proxmox_api_url = "https://65.109.61.237:8006/api2/json"  # Your Proxmox IP Address
proxmox_node = "rs-server"
proxmox_api_token_id = "root@pam!iac"  # API Token ID
proxmox_api_token_secret = "bcf6330f-37cc-4dcb-81bb-29a02c26e769" # API Token

proxmox_storage      = "local"
cpu_type             = "host"
talos_version        = "v1.8.2"
base_iso_file        = "local:iso/archlinux-2024.10.01-x86_64.iso"
------------------------------- # Print file contents as-is
-------------------------------


./packer/talos-packer/proxmox.pkr.hcl # Print the file path
-------------------------------
packer {
  required_plugins {
    proxmox = {
      version = ">= 1.0.1"
      source  = "github.com/hashicorp/proxmox"
    }
  }
}

source "proxmox-iso" "talos" {
  proxmox_url              = var.proxmox_api_url
  username                 = var.proxmox_api_token_id
  token                    = var.proxmox_api_token_secret
  node                     = var.proxmox_node
  insecure_skip_tls_verify = true
  communicator             = "none"

  iso_file    = "${var.base_iso_file}"
  unmount_iso = true

  scsi_controller = "virtio-scsi-single"
  network_adapters {
    bridge = "vmbr1"
    model  = "e1000"
    firewall = true
  }
  disks {
    type              = "scsi"
    storage_pool      = var.proxmox_storage
    format            = "qcow2"
    disk_size         = "1500M"
    io_thread         = true
    cache_mode        = "writethrough"
  }

  memory               = 2048
  vm_id                = "9700"
  cores                = var.cores
  cpu_type             = var.cpu_type
  sockets              = "1"
  ssh_username         = "root"
  ssh_password         = "packer"
  ssh_timeout          = "15m"

  cloud_init              = true
  cloud_init_storage_pool = var.cloudinit_storage_pool

  template_name        = "talos-${var.talos_version}-cloud-init-template"
  template_description = "Talos ${var.talos_version} cloud-init, built on ${formatdate("YYYY-MM-DD hh:mm:ss ZZZ", timestamp())}"

  boot_wait = "25s"
  boot_command = [
    "<enter><wait1m>",
    "passwd<enter><wait>packer<enter><wait>packer<enter><wait15s>",
    "curl -s -L ${local.image} -o /tmp/talos.raw.xz<enter><wait2m>",
    "xz -d -c /tmp/talos.raw.xz | dd of=/dev/sda && sync<enter><wait2m>"
  ]
}

build {
  sources = ["source.proxmox-iso.talos"]
} # Print file contents as-is
-------------------------------


./packer/talos-packer/variables.pkr.hcl # Print the file path
-------------------------------
variable "proxmox_api_token_id" {
  type = string
}

variable "proxmox_api_token_secret" {
  type = string
}

variable "proxmox_api_url" {
  type = string
}

variable "proxmox_node" {
  type = string
}

variable "proxmox_storage" {
  type = string
}

variable "cpu_type" {
  type    = string
  default = "host"
}

variable "cores" {
  type    = string
  default = "2"
}

variable "cloudinit_storage_pool" {
  type    = string
  default = "local"
}

variable "base_iso_file" {
  type    = string
}

variable "talos_version" {
  type    = string
  default = "v1.8.2"
}

variable "talos_disk_image_id" {
  type    = string
}

locals {
  image = "https://factory.talos.dev/image/${var.talos_disk_image_id}/${var.talos_version}/nocloud-amd64.raw.xz"
} # Print file contents as-is
-------------------------------

